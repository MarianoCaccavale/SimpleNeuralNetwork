{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from ActivationFunction import *\n",
    "from Net.Layer import *\n",
    "from Net.FullConnectedNeuralNetworkBProp import *\n",
    "from Net.FullConnectedNeuralNetworkRProp import *\n",
    "from ActivationFunction.ActivationFunction import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Campioni di training: 19999; # Campioni di test: 9999\n"
     ]
    }
   ],
   "source": [
    "test_data_pd = pd.read_csv(\"./Dataset/mnist_test.csv\")\n",
    "train_data_pd = pd.read_csv(\"./Dataset/mnist_train_small.csv\")\n",
    "columns = [\"label\"]\n",
    "pixels = [f\"pixel {pixel}\" for pixel in range(1, 785)]\n",
    "columns = columns + pixels\n",
    "\n",
    "test_data_pd.columns = columns\n",
    "train_data_pd.columns = columns\n",
    "\n",
    "print(f\"# Campioni di training: {len(train_data_pd)}; # Campioni di test: {len(test_data_pd)}\")\n",
    "\n",
    "def one_hot_encoding(Y):\n",
    "  one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "  one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "  return one_hot_Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(10, 100)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array(train_data_pd)\n",
    "test_data = np.array(test_data_pd)\n",
    "\n",
    "# piccolo shuffle di cortesia\n",
    "np.random.shuffle(train_data)\n",
    "np.random.shuffle(test_data)\n",
    "rows, cols = test_data.shape\n",
    "\n",
    "val_data = test_data[0:2500]\n",
    "# test_data = test_data[2500:rows+1]\n",
    "\n",
    "# X_train = train_data[:, 1:train_data.shape[1]+1].T\n",
    "X_train = train_data[:100, 1:train_data.shape[1]+1].T\n",
    "# Y_train = train_data[:, 0]\n",
    "Y_train = train_data[:100, 0]\n",
    "Y_train = one_hot_encoding(Y_train)\n",
    "\n",
    "X_test = test_data[:, 1:test_data.shape[1]+1].T\n",
    "Y_test = test_data[:, 0]\n",
    "Y_test = one_hot_encoding(Y_test)\n",
    "\n",
    "X_val = val_data[:, 1:val_data.shape[1]+1]\n",
    "Y_val = val_data[:, 0]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Layer(784, 256, SigmoidActivationFunction)\n",
    "output_layer = Layer(256, 10, SoftMaxActivationFunction)\n",
    "layers = [input_layer, output_layer]\n",
    "\n",
    "nn = FullConnectedNeuralNetworkBprop(layers, SumOfSquaredError, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.train(X_train, Y_train, validation_set=X_test, validation_targets=Y_test, epochs=20, training_method=TrainingMethod.BATCH)\n",
    "print(f\"Final accuracy = {nn.accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 100 samples\n",
      "Fine epoch #0; mean_train_error = 0.47932634 - mean_val_error: 0.47875222 - accuracy = 0.12000000\n",
      "Fine epoch #1; mean_train_error = 0.86000000 - mean_val_error: 0.89728973 - accuracy = 0.14120000\n",
      "Fine epoch #2; mean_train_error = 0.89999766 - mean_val_error: 0.90418796 - accuracy = 0.10141200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m layers \u001b[38;5;241m=\u001b[39m [input_layer, output_layer]\n\u001b[0;32m      5\u001b[0m rprop_nn \u001b[38;5;241m=\u001b[39m FullConnectedNeuralNetworkRprop(layers, SumOfSquaredError)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mrprop_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\OneDrive\\Documenti\\Università\\Università\\Magistrale\\Neural Networks and Deep Learning\\SimpleNeuralNetwork\\Net\\FullConnectedNeuralNetwork.py:112\u001b[0m, in \u001b[0;36mFullConnectedNeuralNetwork.train\u001b[1;34m(self, training_set, ground_truths, epochs, training_method, validation_set, validation_targets, batch_size)\u001b[0m\n\u001b[0;32m    110\u001b[0m   sum_of_weights_delta, sum_of_biases_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_back_propagate(ground_truth)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m   weights_delta, biases_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_back_propagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sum_of_weights_delta)):\n\u001b[0;32m    115\u001b[0m     sum_of_weights_delta[i] \u001b[38;5;241m=\u001b[39m sum_of_weights_delta[i] \u001b[38;5;241m+\u001b[39m weights_delta[i]\n",
      "File \u001b[1;32mc:\\Users\\maria\\OneDrive\\Documenti\\Università\\Università\\Magistrale\\Neural Networks and Deep Learning\\SimpleNeuralNetwork\\Net\\FullConnectedNeuralNetworkRProp.py:88\u001b[0m, in \u001b[0;36mFullConnectedNeuralNetworkRprop._back_propagate\u001b[1;34m(self, ground_truth)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_gradient_per_layer[layer_index] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m   gradient_change \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_gradient_change(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_gradient_per_layer[layer_index], dCdW)\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_step_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_change\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m dw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msign(dCdW), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_sizes[layer_index])\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_change \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\maria\\OneDrive\\Documenti\\Università\\Università\\Magistrale\\Neural Networks and Deep Learning\\SimpleNeuralNetwork\\Net\\FullConnectedNeuralNetworkRProp.py:-1\u001b[0m, in \u001b[0;36mFullConnectedNeuralNetworkRprop._update_step_size\u001b[1;34m(self, layer_index, gradient_change)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_layer = Layer(784, 256, SigmoidActivationFunction)\n",
    "output_layer = Layer(256, 10, SoftMaxActivationFunction)\n",
    "layers = [input_layer, output_layer]\n",
    "\n",
    "rprop_nn = FullConnectedNeuralNetworkRprop(layers, SumOfSquaredError)\n",
    "rprop_nn.train(X_train, Y_train, validation_set=X_test, validation_targets=Y_test, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_encoded_rprop_nn = FullConnectedNeuralNetworkRprop([Layer(784, 256, SigmoidActivationFunction),\n",
    "                                                        Layer(256, 10, SoftMaxActivationFunction)],\n",
    "                                                        CrossEntropy,\n",
    "                                                        learning_rate = 1,\n",
    "                                                        rprop_eta_minus=0.0001,\n",
    "                                                        rprop_eta_plus=2\n",
    "                                                        )\n",
    "not_encoded_rprop_nn.train(X_train, Y_train, validation_set=X_test, validation_targets=Y_test, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_size = [627, 470, 392, 313, 156]\n",
    "number_of_epoch_encoder = 300\n",
    "number_of_training_epochs = 150\n",
    "encoder_layer_size = encoder_size[0]\n",
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprop_encoder = FullConnectedNeuralNetworkBprop([Layer(784, encoder_layer_size, LeakyRELUActivationFunction),\n",
    "                                                 Layer(encoder_layer_size, 784, RELUActivationFunction)\n",
    "                                                 ], SumOfSquaredError, 0.00005)\n",
    "\n",
    "rprop_encoder.train(X_train, X_train, number_of_epoch_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 2\n",
    "plt.imshow(X_train[:, sample_index].reshape([28, 28]))\n",
    "plt.show()\n",
    "plt.imshow(rprop_encoder.predict(X_train[:, sample_index]).reshape([28, 28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = FullConnectedNeuralNetwork([rprop_encoder.layers[0]], SumOfSquaredError)\n",
    "\n",
    "X_encoded_train = np.empty([encoder_layer_size, X_train.shape[1]])\n",
    "Y_encoded_train = Y_train\n",
    "for X_sample in X_train.T:\n",
    "  X_encoded_train[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_train.shape)\n",
    "print(X_encoded_train.shape)\n",
    "\n",
    "X_encoded_test = np.empty([encoder_layer_size, X_test.shape[1]])\n",
    "Y_encoded_test = Y_test\n",
    "for X_sample in X_test.T:\n",
    "  X_encoded_test[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_test.shape)\n",
    "print(X_encoded_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_rprop_nn = FullConnectedNeuralNetworkRprop([Layer(encoder_layer_size, 256, SigmoidActivationFunction),\n",
    "                                                    Layer(256, 10, SoftMaxActivationFunction)],\n",
    "                                                   CrossEntropy,\n",
    "                                                   )\n",
    "encoded_rprop_nn.train(X_encoded_train, Y_encoded_train, validation_set=X_encoded_test, validation_targets=Y_encoded_test, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_rprop_nn = FullConnectedNeuralNetworkRprop([Layer(encoder_layer_size, 256, SigmoidActivationFunction),\n",
    "                                                    Layer(256, 10, SoftMaxActivationFunction)],\n",
    "                                                   CrossEntropy,\n",
    "                                                   learning_rate = 1,\n",
    "                                                   rprop_eta_minus=0.0001,\n",
    "                                                   rprop_eta_plus=2\n",
    "                                                    )\n",
    "encoded_rprop_nn.train(X_encoded_train, Y_encoded_train, validation_set=X_encoded_test, validation_targets=Y_encoded_test, number_of_training_epochs=20)\n",
    "\n",
    "metrics[f\"{encoder_layer_size}\"] = {\"train_errors\":encoded_rprop_nn.mean_train_error,\n",
    "                                    \"val_errors\":encoded_rprop_nn.mean_val_error,\n",
    "                                    \"accuracy\":encoded_rprop_nn.accuracies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer_size = encoder_size[0]\n",
    "rprop_encoder = FullConnectedNeuralNetworkBprop([Layer(784, encoder_layer_size, LeakyRELUActivationFunction),\n",
    "                                                 Layer(encoder_layer_size, 784, RELUActivationFunction)\n",
    "                                                 ], SumOfSquaredError, 0.00005)\n",
    "\n",
    "rprop_encoder.train(X_train[], X_train[], number_of_epoch_encoder)\n",
    "\n",
    "sample_index = 1\n",
    "plt.imshow(X_train[:, sample_index].reshape([28, 28]))\n",
    "plt.show()\n",
    "plt.imshow(rprop_encoder.predict(X_train[:, sample_index]).reshape([28, 28]))\n",
    "plt.show()\n",
    "\n",
    "encoder = FullConnectedNeuralNetwork([rprop_encoder.layers[0]], SumOfSquaredError)\n",
    "\n",
    "X_encoded_train = np.empty([encoder_layer_size, X_train.shape[1]])\n",
    "Y_encoded_train = Y_train\n",
    "for X_sample in X_train.T:\n",
    "  X_encoded_train[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_train.shape)\n",
    "print(X_encoded_train.shape)\n",
    "\n",
    "X_encoded_test = np.empty([encoder_layer_size, X_test.shape[1]])\n",
    "Y_encoded_test = Y_test\n",
    "for X_sample in X_test.T:\n",
    "  X_encoded_test[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_test.shape)\n",
    "print(X_encoded_test.shape)\n",
    "\n",
    "encoded_rprop_nn = FullConnectedNeuralNetworkRprop([Layer(encoder_layer_size, 256, SigmoidActivationFunction),\n",
    "                                                    Layer(256, 10, SoftMaxActivationFunction)],\n",
    "                                                   CrossEntropy,\n",
    "                                                   learning_rate = 1,\n",
    "                                                   rprop_eta_minus=0.0001,\n",
    "                                                   rprop_eta_plus=2\n",
    "                                                    )\n",
    "encoded_rprop_nn.train(X_encoded_train, Y_encoded_train, validation_set=X_encoded_test, validation_targets=Y_encoded_test, number_of_training_epochs=20)\n",
    "\n",
    "metrics[f\"{encoder_layer_size}\"] = {\"train_errors\":encoded_rprop_nn.mean_train_error,\n",
    "                                    \"val_errors\":encoded_rprop_nn.mean_val_error,\n",
    "                                    \"accuracy\":encoded_rprop_nn.accuracies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer_size = encoder_size[1]\n",
    "rprop_encoder = FullConnectedNeuralNetworkBprop([Layer(784, encoder_layer_size, LeakyRELUActivationFunction),\n",
    "                                                 Layer(encoder_layer_size, 784, RELUActivationFunction)\n",
    "                                                 ], SumOfSquaredError, 0.00005)\n",
    "\n",
    "rprop_encoder.train(X_train, X_train, number_of_epoch_encoder)\n",
    "\n",
    "sample_index = 1\n",
    "plt.imshow(X_train[:, sample_index].reshape([28, 28]))\n",
    "plt.show()\n",
    "plt.imshow(rprop_encoder.predict(X_train[:, sample_index]).reshape([28, 28]))\n",
    "plt.show()\n",
    "\n",
    "encoder = FullConnectedNeuralNetwork([rprop_encoder.layers[0]], SumOfSquaredError)\n",
    "\n",
    "X_encoded_train = np.empty([encoder_layer_size, X_train.shape[1]])\n",
    "Y_encoded_train = Y_train\n",
    "for X_sample in X_train.T:\n",
    "  X_encoded_train[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_train.shape)\n",
    "print(X_encoded_train.shape)\n",
    "\n",
    "X_encoded_test = np.empty([encoder_layer_size, X_test.shape[1]])\n",
    "Y_encoded_test = Y_test\n",
    "for X_sample in X_test.T:\n",
    "  X_encoded_test[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_test.shape)\n",
    "print(X_encoded_test.shape)\n",
    "\n",
    "encoded_rprop_nn = FullConnectedNeuralNetworkRprop([Layer(encoder_layer_size, 256, SigmoidActivationFunction),\n",
    "                                                    Layer(256, 10, SoftMaxActivationFunction)],\n",
    "                                                   CrossEntropy,\n",
    "                                                   learning_rate = 1,\n",
    "                                                   rprop_eta_minus=0.0001,\n",
    "                                                   rprop_eta_plus=2\n",
    "                                                    )\n",
    "encoded_rprop_nn.train(X_encoded_train, Y_encoded_train, validation_set=X_encoded_test, validation_targets=Y_encoded_test, number_of_training_epochs=20)\n",
    "\n",
    "metrics[f\"{encoder_layer_size}\"] = {\"train_errors\":encoded_rprop_nn.mean_train_error,\n",
    "                                    \"val_errors\":encoded_rprop_nn.mean_val_error,\n",
    "                                    \"accuracy\":encoded_rprop_nn.accuracies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer_size = encoder_size[2]\n",
    "rprop_encoder = FullConnectedNeuralNetworkBprop([Layer(784, encoder_layer_size, LeakyRELUActivationFunction),\n",
    "                                                 Layer(encoder_layer_size, 784, RELUActivationFunction)\n",
    "                                                 ], SumOfSquaredError, 0.00005)\n",
    "\n",
    "rprop_encoder.train(X_train, X_train, number_of_epoch_encoder)\n",
    "\n",
    "sample_index = 1\n",
    "plt.imshow(X_train[:, sample_index].reshape([28, 28]))\n",
    "plt.show()\n",
    "plt.imshow(rprop_encoder.predict(X_train[:, sample_index]).reshape([28, 28]))\n",
    "plt.show()\n",
    "\n",
    "encoder = FullConnectedNeuralNetwork([rprop_encoder.layers[0]], SumOfSquaredError)\n",
    "\n",
    "X_encoded_train = np.empty([encoder_layer_size, X_train.shape[1]])\n",
    "Y_encoded_train = Y_train\n",
    "for X_sample in X_train.T:\n",
    "  X_encoded_train[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_train.shape)\n",
    "print(X_encoded_train.shape)\n",
    "\n",
    "X_encoded_test = np.empty([encoder_layer_size, X_test.shape[1]])\n",
    "Y_encoded_test = Y_test\n",
    "for X_sample in X_test.T:\n",
    "  X_encoded_test[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_test.shape)\n",
    "print(X_encoded_test.shape)\n",
    "\n",
    "encoded_rprop_nn = FullConnectedNeuralNetworkRprop([Layer(encoder_layer_size, 256, SigmoidActivationFunction),\n",
    "                                                    Layer(256, 10, SoftMaxActivationFunction)],\n",
    "                                                   CrossEntropy,\n",
    "                                                   learning_rate = 1,\n",
    "                                                   rprop_eta_minus=0.0001,\n",
    "                                                   rprop_eta_plus=2\n",
    "                                                    )\n",
    "encoded_rprop_nn.train(X_encoded_train, Y_encoded_train, validation_set=X_encoded_test, validation_targets=Y_encoded_test, number_of_training_epochs=20)\n",
    "\n",
    "metrics[f\"{encoder_layer_size}\"] = {\"train_errors\":encoded_rprop_nn.mean_train_error,\n",
    "                                    \"val_errors\":encoded_rprop_nn.mean_val_error,\n",
    "                                    \"accuracy\":encoded_rprop_nn.accuracies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer_size = encoder_size[3]\n",
    "rprop_encoder = FullConnectedNeuralNetworkBprop([Layer(784, encoder_layer_size, LeakyRELUActivationFunction),\n",
    "                                                 Layer(encoder_layer_size, 784, RELUActivationFunction)\n",
    "                                                 ], SumOfSquaredError, 0.00005)\n",
    "\n",
    "rprop_encoder.train(X_train, X_train, number_of_epoch_encoder)\n",
    "\n",
    "sample_index = 1\n",
    "plt.imshow(X_train[:, sample_index].reshape([28, 28]))\n",
    "plt.show()\n",
    "plt.imshow(rprop_encoder.predict(X_train[:, sample_index]).reshape([28, 28]))\n",
    "plt.show()\n",
    "\n",
    "encoder = FullConnectedNeuralNetwork([rprop_encoder.layers[0]], SumOfSquaredError)\n",
    "\n",
    "X_encoded_train = np.empty([encoder_layer_size, X_train.shape[1]])\n",
    "Y_encoded_train = Y_train\n",
    "for X_sample in X_train.T:\n",
    "  X_encoded_train[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_train.shape)\n",
    "print(X_encoded_train.shape)\n",
    "\n",
    "X_encoded_test = np.empty([encoder_layer_size, X_test.shape[1]])\n",
    "Y_encoded_test = Y_test\n",
    "for X_sample in X_test.T:\n",
    "  X_encoded_test[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_test.shape)\n",
    "print(X_encoded_test.shape)\n",
    "\n",
    "encoded_rprop_nn = FullConnectedNeuralNetworkRprop([Layer(encoder_layer_size, 256, SigmoidActivationFunction),\n",
    "                                                    Layer(256, 10, SoftMaxActivationFunction)],\n",
    "                                                   CrossEntropy,\n",
    "                                                   learning_rate = 1,\n",
    "                                                   rprop_eta_minus=0.0001,\n",
    "                                                   rprop_eta_plus=2\n",
    "                                                    )\n",
    "encoded_rprop_nn.train(X_encoded_train, Y_encoded_train, validation_set=X_encoded_test, validation_targets=Y_encoded_test, number_of_training_epochs=20)\n",
    "\n",
    "metrics[f\"{encoder_layer_size}\"] = {\"train_errors\":encoded_rprop_nn.mean_train_error,\n",
    "                                    \"val_errors\":encoded_rprop_nn.mean_val_error,\n",
    "                                    \"accuracy\":encoded_rprop_nn.accuracies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer_size = encoder_size[4]\n",
    "rprop_encoder = FullConnectedNeuralNetworkBprop([Layer(784, encoder_layer_size, LeakyRELUActivationFunction),\n",
    "                                                 Layer(encoder_layer_size, 784, RELUActivationFunction)\n",
    "                                                 ], SumOfSquaredError, 0.00005)\n",
    "\n",
    "rprop_encoder.train(X_train, X_train, number_of_epoch_encoder)\n",
    "\n",
    "sample_index = 1\n",
    "plt.imshow(X_train[:, sample_index].reshape([28, 28]))\n",
    "plt.show()\n",
    "plt.imshow(rprop_encoder.predict(X_train[:, sample_index]).reshape([28, 28]))\n",
    "plt.show()\n",
    "\n",
    "encoder = FullConnectedNeuralNetwork([rprop_encoder.layers[0]], SumOfSquaredError)\n",
    "\n",
    "X_encoded_train = np.empty([encoder_layer_size, X_train.shape[1]])\n",
    "Y_encoded_train = Y_train\n",
    "for X_sample in X_train.T:\n",
    "  X_encoded_train[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_train.shape)\n",
    "print(X_encoded_train.shape)\n",
    "\n",
    "X_encoded_test = np.empty([encoder_layer_size, X_test.shape[1]])\n",
    "Y_encoded_test = Y_test\n",
    "for X_sample in X_test.T:\n",
    "  X_encoded_test[:, 0] = encoder.predict(X_sample)\n",
    "\n",
    "print(X_encoded_test.shape)\n",
    "print(X_encoded_test.shape)\n",
    "\n",
    "encoded_rprop_nn = FullConnectedNeuralNetworkRprop([Layer(encoder_layer_size, 256, SigmoidActivationFunction),\n",
    "                                                    Layer(256, 10, SoftMaxActivationFunction)],\n",
    "                                                   CrossEntropy,\n",
    "                                                   learning_rate = 1,\n",
    "                                                   rprop_eta_minus=0.0001,\n",
    "                                                   rprop_eta_plus=2\n",
    "                                                    )\n",
    "encoded_rprop_nn.train(X_encoded_train, Y_encoded_train, validation_set=X_encoded_test, validation_targets=Y_encoded_test, number_of_training_epochs=20)\n",
    "\n",
    "metrics[f\"{encoder_layer_size}\"] = {\"train_errors\":encoded_rprop_nn.mean_train_error,\n",
    "                                    \"val_errors\":encoded_rprop_nn.mean_val_error,\n",
    "                                    \"accuracy\":encoded_rprop_nn.accuracies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
